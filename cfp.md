---
layout: default
---

# Call for Papers

<style>
.foo {
    table-layout: fixed;
    width: 100%;
}
</style>

<table class="foo">  
  <tr>
    <td width="30%"><b>Submission Deadline</b></td>
    <td width="70%">February 26, 2021 Anywhere on Earth (AoE)</td>
  </tr>
  <tr>
    <td><b>Author notification</b></td>
    <td>March 26, 2021 Anywhere on Earth (AoE)</td>
  </tr>
  <tr>
    <td><b>Camera ready deadline</b></td>
    <td>April 26, 2021 Anywhere on Earth (AoE)</td>
  </tr>
  <tr>
    <td><b>Submission server</b></td>
    <td>
    <a href="https://cmt3.research.microsoft.com/ICLRsecml2021">https://cmt3.research.microsoft.com/ICLRsecml2021</a>
    </td>
  </tr>
  <tr>
    <td><b>Submission format</b></td>
    <td>Submissions need to be anonymized, and use the latex template <a href="https://drive.google.com/file/d/1kUKsWKKzrKCUnlhMy3GEDomSdkdU9wx4/view?usp=sharing">here</a>, modified from the template for ICLR conference papers. Submissions should include at most <b>4</b> pages, excluding the references and appendices.</td>
  </tr>  
</table>

We invite submissions on any aspect of ML security and safety. Topics include but are not limited to:

- Adversarial attacks against ML systems, including training and test time attacks
- Improving model robustness against attacks, including empirical and certifiable defenses
- Theoretical understanding of adversarial machine learning
- AI safety for real-world deployment
- Formal verification of machine learning systems
- Explainable and interpretable AI
- Futuristic concerns about AI safety

We only consider submissions that haven’t been published in any peer-reviewed venue, including ICLR 2021 conference. The workshop is non-archival and will not have any official proceedings.

Based on the PC’s recommendation, the accepted papers will be allocated either a contributed talk or a poster presentation. We will offer a best paper award.
